{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP9517 group project\r\n",
    "# CV2 3.4.2.17\r\n",
    "# numpy 1.21.2\r\n",
    "# skimage 0.18.3\r\n",
    "# matplotlib 3.4.3 \r\n",
    "\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math\r\n",
    "import skimage.segmentation\r\n",
    "from skimage import color\r\n",
    "from pathlib import Path\r\n",
    "from collections import defaultdict\r\n",
    "from scipy.optimize import linear_sum_assignment\r\n",
    "from pyefd import elliptic_fourier_descriptors\r\n",
    "\r\n",
    "import imageio.core.util\r\n",
    "\r\n",
    "\r\n",
    "def ignore_warnings(*args, **kwargs):\r\n",
    "    pass\r\n",
    "imageio.core.util._precision_warn = ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\r\n",
    "\r\n",
    "    # used for handling object information. Scalable.\r\n",
    "\r\n",
    "    split_threshold = 2.5\r\n",
    "    def __init__(self,contour,centroid,area,id = -1):\r\n",
    "        self.contour = contour # a set of (x,y) coordinates making up  a contour\r\n",
    "        self.id = id\r\n",
    "        self.area = area\r\n",
    "        self.centroid = centroid #(x,y) co-ordinates\r\n",
    "        self.missing_span = 0\r\n",
    "        self.major = 0\r\n",
    "        self.minor = 0\r\n",
    "\r\n",
    "        self.underSplitting = False\r\n",
    "\r\n",
    "    def get_contours(self):\r\n",
    "        return self.contour\r\n",
    "\r\n",
    "    def get_area(self):\r\n",
    "        return self.area\r\n",
    "\r\n",
    "    def get_cell_id(self):\r\n",
    "        return self.id\r\n",
    "\r\n",
    "    def get_centroid(self):\r\n",
    "        return self.centroid\r\n",
    "\r\n",
    "    def get_under_splitting(self):\r\n",
    "        return self.underSplitting\r\n",
    "\r\n",
    "    def set_cell_id(self,new_id):\r\n",
    "        self.id = new_id\r\n",
    "\r\n",
    "    def set_under_splitting(self,flag):\r\n",
    "        self.underSplitting = flag\r\n",
    "\r\n",
    "    def if_splitting(self):\r\n",
    "        (x,y),(a,b), angle = cv2.fitEllipse(self.contour)\r\n",
    "        ratio = b / a\r\n",
    "\r\n",
    "        if(ratio > self.split_threshold):\r\n",
    "                self.set_under_splitting(True)\r\n",
    "\r\n",
    "        self.major = b\r\n",
    "        self.minor = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame:\r\n",
    "\r\n",
    "    def __init__(self, image):\r\n",
    "        self.image = image\r\n",
    "        self.cell_list = []\r\n",
    "        self.trajectory = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match:\r\n",
    "\r\n",
    "    distance_threshold = 50 # used for normalizing & threshold\r\n",
    "\r\n",
    "    alpha_1 = 0.4\r\n",
    "    alpha_2 = 0.6\r\n",
    "    distance_matrix = []\r\n",
    "    cost_matrix = []\r\n",
    "    shape_matrix = []\r\n",
    "    child = []\r\n",
    "\r\n",
    "    def __init__(self,frame_pre,frame_now):\r\n",
    "        self.frame_pre = frame_pre\r\n",
    "        self.frame_now = frame_now\r\n",
    "\r\n",
    "    def set_distance_threshold(self,new_threshold):\r\n",
    "        self.distance_threshold = new_threshold\r\n",
    "\r\n",
    "    def set_distance_factor(self,new_factor):\r\n",
    "        self.alpha_1 = new_factor\r\n",
    "\r\n",
    "    def set_shape_factor(self,new_factor):\r\n",
    "        self.alpha_2 = new_factor\r\n",
    "\r\n",
    "    def cal_distance_cost(self):\r\n",
    "\r\n",
    "        size_pre = len(self.frame_pre.cell_list)\r\n",
    "        size_now = len(self.frame_now.cell_list)\r\n",
    "\r\n",
    "        distance_matrix = np.zeros((size_pre, size_now))\r\n",
    "\r\n",
    "        # Euclidean Distance\r\n",
    "        for i in range(size_pre):\r\n",
    "            for j in range(size_now):\r\n",
    "                x1, y1 = self.frame_pre.cell_list[i].centroid\r\n",
    "                x2, y2 = self.frame_now.cell_list[j].centroid\r\n",
    "                distance = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\r\n",
    "                distance_matrix[i][j] = distance / self.distance_threshold if distance < self.distance_threshold \\\r\n",
    "                    else 1\r\n",
    "\r\n",
    "        self.distance_matrix = distance_matrix\r\n",
    "\r\n",
    "    def cal_shape_cost(self):\r\n",
    "        size_pre = len(self.frame_pre.cell_list)\r\n",
    "        size_now = len(self.frame_now.cell_list)\r\n",
    "\r\n",
    "        shape_matrix = np.zeros((size_pre, size_now))\r\n",
    "\r\n",
    "        for i in range(size_pre):\r\n",
    "            for j in range(size_now):\r\n",
    "                cell_pre = pre_frame.cell_list[i]\r\n",
    "                cell_now = now_frame.cell_list[j]\r\n",
    "\r\n",
    "                pre_coeffs = elliptic_fourier_descriptors(cell_pre.contour, order=8, normalize=True)\r\n",
    "                now_coeffs = elliptic_fourier_descriptors(cell_now.contour, order=8, normalize=True)\r\n",
    "\r\n",
    "                similarity = 0\r\n",
    "                for k in range(np.shape(pre_coeffs)[0]):\r\n",
    "                    vec_pre = pre_coeffs[k,:]\r\n",
    "                    vec_now = now_coeffs[k,:]\r\n",
    "                    similarity += np.linalg.norm(vec_pre - vec_now)\r\n",
    "\r\n",
    "                shape_matrix[i][j] = similarity\r\n",
    "\r\n",
    "\r\n",
    "        self.shape_matrix = shape_matrix\r\n",
    "\r\n",
    "    def cal_cost_matrix(self):\r\n",
    "        self.cal_distance_cost()\r\n",
    "        self.cal_shape_cost()\r\n",
    "        cost_matrix = self.alpha_1 * self.distance_matrix \\\r\n",
    "                        + self.alpha_2 * self.shape_matrix\r\n",
    "        # print(cost_matrix)\r\n",
    "        self.cost_matrix = cost_matrix\r\n",
    "\r\n",
    "\r\n",
    "    def match(self):\r\n",
    "        self.cal_cost_matrix()\r\n",
    "        cost_matrix = self.cost_matrix\r\n",
    "        match_result = linear_sum_assignment(self.cost_matrix)\r\n",
    "\r\n",
    "        shape = np.shape(match_result)\r\n",
    "        match_list = []\r\n",
    "        for i in range(shape[1]):\r\n",
    "            node_pre = match_result[0][i]\r\n",
    "            node_now = match_result[1][i]\r\n",
    "            pre_cell = pre_frame.cell_list[node_pre]\r\n",
    "            now_cell = now_frame.cell_list[node_now]\r\n",
    "\r\n",
    "            if(self.distance_matrix[node_pre][node_now] == 1):\r\n",
    "                continue\r\n",
    "\r\n",
    "            match_list.append([node_pre,node_now])\r\n",
    "\r\n",
    "        return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary(\r\n",
    "    input_image: np.array, \r\n",
    "    min_cell_pixel_portion = 1/8, \r\n",
    "    threshold_block_size = 35\r\n",
    "):\r\n",
    "    '''\r\n",
    "    min_cell_pixel_portion: Decreasing this value will make smaller pixel value chunks considered as cell\r\n",
    "    threshold_block_size: Increasing this value will let larger size of chunk being considered as cell, \r\n",
    "    but will lose detailed edges at the same time\r\n",
    "    '''\r\n",
    "    input = input_image.copy()\r\n",
    "    # Get meaningful range\r\n",
    "    meaningful_range = np.max(input) - np.min(input)\r\n",
    "    # Assume certain small portion of the max_pixel_value is the minimum cell pixel value\r\n",
    "    min_cell_pixel = math.ceil(meaningful_range * min_cell_pixel_portion)\r\n",
    "    # normalize image based on the acquired meaningful range\r\n",
    "    input_norm = cv2.normalize(input, None, alpha=0, beta=meaningful_range, norm_type=cv2.NORM_MINMAX)\r\n",
    "    input_norm[input_norm < min_cell_pixel] = 0\r\n",
    "    input_binary = cv2.adaptiveThreshold(\r\n",
    "        input_norm,meaningful_range,\r\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\r\n",
    "        cv2.THRESH_BINARY,\r\n",
    "        threshold_block_size,\r\n",
    "        0\r\n",
    "    )\r\n",
    "    return input_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduce_noise_by_closing(input_binary: np.array, kernel_size_closing = (5,5), iterations = 5):\r\n",
    "    '''\r\n",
    "    Try dilate and erode: closing\r\n",
    "    1. Dilate the objects first to get rid of the noise inside each objects\r\n",
    "    2. Erode the objects with same degree to decrease the size to original state\r\n",
    "    '''\r\n",
    "    input_closing = input_binary.copy()\r\n",
    "    kernel = np.ones(kernel_size_closing,np.uint8)\r\n",
    "    input_closing = cv2.morphologyEx(input_closing, cv2.MORPH_CLOSE, kernel, iterations)\r\n",
    "    return input_closing\r\n",
    "\r\n",
    "def get_reduce_noise_by_opening(input_binary: np.array, kernel_size_opening = (7,7), iterations = 5):\r\n",
    "    '''\r\n",
    "    Try erode and dilate: opening\r\n",
    "    Erode then dilate\r\n",
    "    '''\r\n",
    "    input_opening = input_binary.copy()\r\n",
    "    kernel = np.ones(kernel_size_opening,np.uint8)\r\n",
    "    input_opening = cv2.morphologyEx(input_opening, cv2.MORPH_OPEN, kernel, iterations)\r\n",
    "    return input_opening\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(\r\n",
    "        input_image: np.array,\r\n",
    "        input_binary: np.array, \r\n",
    "        kernel_size_bg = (3, 3),\r\n",
    "        iterations_bg = 7,\r\n",
    "        kernel_size_dist_erode = (3, 3),\r\n",
    "        iterations_dist_erode = 4\r\n",
    "    ):\r\n",
    "    global markers_color_value_offset\r\n",
    "    '''\r\n",
    "    Find all of the contours of the input image cell and draw the contours\r\n",
    "    '''\r\n",
    "    kernel = np.ones(kernel_size_bg, np.uint8)\r\n",
    "    sure_bg = cv2.dilate(input_binary, kernel, iterations=iterations_bg)\r\n",
    "    dist_transform = cv2.distanceTransform(input_binary,cv2.DIST_MASK_3,5)\r\n",
    "    dist_transform_erode = cv2.erode(dist_transform, kernel_size_dist_erode, iterations = iterations_dist_erode)\r\n",
    "    sure_fg = np.uint8(dist_transform_erode)  #Convert to uint8 from float\r\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\r\n",
    "    markers_amount, markers = cv2.connectedComponents(\r\n",
    "        sure_fg, \r\n",
    "        4 # use connectivity of 4 instead of 8 to decrease close cells attaching probability\r\n",
    "    )\r\n",
    "    '''\r\n",
    "    object_amount_not_on_borders:\r\n",
    "    1. The total amount of objects detected in the image without considering the ones on borders\r\n",
    "    2. Need to use markers_amount - 1 since markers_amount includes the background\r\n",
    "    '''\r\n",
    "    object_amount_not_on_borders = markers_amount - 1\r\n",
    "\r\n",
    "    # make sure the background are not set as 0 and consider as unsured area\r\n",
    "    markers = markers + markers_color_value_offset\r\n",
    "    max_unkown = np.max(unknown)\r\n",
    "    markers[unknown==max_unkown] = 0\r\n",
    "\r\n",
    "    watershed = cv2.watershed(input_image, markers)\r\n",
    "\r\n",
    "    # watershed boundaries are -1\r\n",
    "    edges = np.zeros(input_binary.shape, np.uint8)\r\n",
    "    edges[watershed == -1] = 1\r\n",
    "\r\n",
    "    #label2rgb - Return an RGB image where color-coded labels are painted over the image.\r\n",
    "    colored_segmentation = color.label2rgb(watershed, bg_label=0)\r\n",
    "\r\n",
    "    return watershed, edges, colored_segmentation, object_amount_not_on_borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_pixel_record(object_color_array):\r\n",
    "    # Get useful pixel values\r\n",
    "    unique_objects = np.unique(object_color_array)\r\n",
    "    unique_objects = unique_objects[unique_objects >= 1] \r\n",
    "\r\n",
    "    # initialize the pixel dict with all object count starting from 0\r\n",
    "    object_dict = dict.fromkeys(unique_objects)\r\n",
    "    for key in object_dict:\r\n",
    "        object_dict[key] = 0\r\n",
    "\r\n",
    "    # get the pixel value count for each object key label\r\n",
    "    for row in object_color_array:\r\n",
    "        for col in row:\r\n",
    "            if col >= 1:\r\n",
    "                object_dict[col] += 1\r\n",
    "    return object_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_segment_info(path_cell: str):\r\n",
    "    # Read as gray\r\n",
    "    cell_original = cv2.imread(path_cell)\r\n",
    "    cell = cv2.imread(path_cell, cv2.IMREAD_GRAYSCALE)\r\n",
    "\r\n",
    "    # Turn into np array first\r\n",
    "    cell = np.array(cell)\r\n",
    "\r\n",
    "    # Grey image to binary\r\n",
    "    cell_binary = get_binary(cell)\r\n",
    "\r\n",
    "    # reduce noise\r\n",
    "    cell_binary_opening = get_reduce_noise_by_opening(cell_binary)\r\n",
    "    cell_no_noise = cell_binary_opening.copy()\r\n",
    "\r\n",
    "    # removing border interfered cells\r\n",
    "    cell_no_border = skimage.segmentation.clear_border(cell_no_noise)\r\n",
    "\r\n",
    "    # get segmentation info WITH cells on boundaries considered\r\n",
    "    cell_watershed, cell_edges, cell_colored_segmentation, cell_amount = find_contours(cell_original, cell_no_noise)\r\n",
    "    # get segmentation info WITHOUT cells on boundaries considered\r\n",
    "    cell_watershed_no_border, cell_edges_no_border, cell_colored_segmentation_no_border, cell_amount_no_border = find_contours(cell_original, cell_no_border)\r\n",
    "    \r\n",
    "    # After minus markers_color_value_offset, all of the objects color pixel will have value >= 1\r\n",
    "    labels = np.unique(cell_watershed_no_border)\r\n",
    "\r\n",
    "    cell_watershed_no_border = cell_watershed_no_border - markers_color_value_offset\r\n",
    "    cell_pixel_dict_no_border = get_object_pixel_record(cell_watershed_no_border)\r\n",
    "    cell_pixel_array_no_border = [v for _, v in cell_pixel_dict_no_border.items() if v >= 0]\r\n",
    "    cell_pixel_size_average = round(sum(cell_pixel_array_no_border) / len(cell_pixel_array_no_border))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "    # Print cell detection result for a single image\r\n",
    "    all_figures = plt.figure(figsize = (13,13))\r\n",
    "    titles = ['cell_original','cell_no_noise','cell_edges','cell_colored_segmentation']\r\n",
    "    images = [cell, cell_no_noise, cell_edges, cell_colored_segmentation]\r\n",
    "    for i in range(4):\r\n",
    "        ax1 = all_figures.add_subplot(2,2,i+1)\r\n",
    "        if i == 3:\r\n",
    "            ax1.imshow(images[i])\r\n",
    "        else:\r\n",
    "            ax1.imshow(images[i], cmap=\"gray\")\r\n",
    "        ax1.set_title(titles[i])\r\n",
    "        ax1.set_axis_off()\r\n",
    "    suptitle = \"Cells count: \" + str(cell_amount) + \", average pixel size: \" + str(cell_pixel_size_average) +\\\r\n",
    "        \", img:\" + path_cell_subfolder + '.' + path_cell_name\r\n",
    "    plt.suptitle(suptitle)\r\n",
    "    plt.tight_layout()\r\n",
    "    output_subfolder_name = \"output1-1/\"\r\n",
    "    plt.savefig(\r\n",
    "        output_subfolder_name +\\\r\n",
    "            path_cell_subfolder + '_' + path_cell_name + \\\r\n",
    "            \", Cells count_\" + str(cell_amount) + \", \" + \\\r\n",
    "            \"average pixel size_\" + str(cell_pixel_size_average) + '.jpg', \r\n",
    "        dpi=400, \r\n",
    "        format='jpg', \r\n",
    "        bbox_inches='tight'\r\n",
    "    )\r\n",
    "    # plt.show()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_name_digits(number: int):\r\n",
    "    number_str = '000'\r\n",
    "    if number < 10:\r\n",
    "        number_str = '00' + str(number)\r\n",
    "    elif number >= 10 and number <= 99: \r\n",
    "        number_str = '0' + str(number)\r\n",
    "    elif number >= 100 and number <= 999:\r\n",
    "        number_str = str(number)\r\n",
    "    else:\r\n",
    "        print(\"TOO BIG NUMBER for format_name_digits:\", number)\r\n",
    "    return number_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_info(path_cell: str):\r\n",
    "    # Read as gray\r\n",
    "    cell_original = cv2.imread(path_cell)\r\n",
    "    cell = cv2.imread(path_cell, cv2.IMREAD_GRAYSCALE)\r\n",
    "\r\n",
    "    # Turn into np array first\r\n",
    "    cell = np.array(cell)\r\n",
    "\r\n",
    "    # Grey image to binary\r\n",
    "    cell_binary = get_binary(cell)\r\n",
    "\r\n",
    "    # reduce noise\r\n",
    "    cell_binary_opening = get_reduce_noise_by_opening(cell_binary)\r\n",
    "    cell_no_noise = cell_binary_opening.copy()\r\n",
    "\r\n",
    "    # removing border interfered cells\r\n",
    "    cell_no_border = skimage.segmentation.clear_border(cell_no_noise)\r\n",
    "\r\n",
    "    # get segmentation info WITH cells on boundaries considered\r\n",
    "    cell_watershed, cell_edges, cell_colored_segmentation, cell_amount = find_contours(cell_original, cell_no_noise)\r\n",
    "\r\n",
    "    # get segmentation info WITHOUT cells on boundaries considered\r\n",
    "    cell_watershed_no_border, cell_edges_no_border, cell_colored_segmentation_no_border, cell_amount_no_border = find_contours(\r\n",
    "        cell_original, cell_no_border)\r\n",
    "\r\n",
    "    # After minus markers_color_value_offset, all of the objects color pixel will have value >= 1\r\n",
    "    labels = np.unique(cell_watershed_no_border)\r\n",
    "\r\n",
    "    cell_watershed_no_border = cell_watershed_no_border - markers_color_value_offset\r\n",
    "\r\n",
    "    labels = np.unique(cell_watershed_no_border)\r\n",
    "    cell_img = np.zeros_like(cell_no_border)\r\n",
    "    cell_img[cell_no_border > 0] = 255\r\n",
    "    cell_img = cv2.cvtColor(cell_img,cv2.COLOR_GRAY2RGB)\r\n",
    "\r\n",
    "    frame = Frame(cell_img)\r\n",
    "    for label in labels:\r\n",
    "        if label <= 0:\r\n",
    "            continue\r\n",
    "        segment = np.zeros_like(cell_watershed_no_border)\r\n",
    "        segment = np.uint8(segment)\r\n",
    "        segment[cell_watershed_no_border == label] = 255\r\n",
    "        _, contours, _ = cv2.findContours(segment, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\r\n",
    "        _, _, stats, centroids = cv2.connectedComponentsWithStats(segment)\r\n",
    "\r\n",
    "        cell = Cell(np.squeeze(contours),centroids[1],stats[1][4])\r\n",
    "\r\n",
    "        # check if the cell is splitting\r\n",
    "        cell.if_splitting()\r\n",
    "        if(cell.area > min_area):\r\n",
    "            frame.cell_list.append(cell)\r\n",
    "\r\n",
    "    return frame\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\r\n",
    "register new cell\r\n",
    "'''\r\n",
    "def register_new_cell(cell:Cell):\r\n",
    "    global cell_id\r\n",
    "    cell.set_cell_id(cell_id)\r\n",
    "    color = np.random.randint(low = 0,high =255,size = 3).tolist()\r\n",
    "    global color_list\r\n",
    "    color_list.append(color)\r\n",
    "    cell_id += 1\r\n",
    "\r\n",
    "def cal_distance(c1,c2):\r\n",
    "    return np.sqrt((c1[0] - c2[0]) ** 2 + (c1[0] - c2[0]) ** 2)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image root path str(Path(file_path).parent.resolve()) + \r\n",
    "image_src_path = str(\".\\Sequences\")\r\n",
    "# individual image path example\\\r\n",
    "path_divide = \"\\\\\"\r\n",
    "path_cell_subfolder = \"01\"\r\n",
    "path_cell_name = \"t000.tif\"\r\n",
    "path_cell = str(image_src_path + path_divide + path_cell_subfolder + path_divide + path_cell_name)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 30\r\n",
    "\r\n",
    "frame_list = []\r\n",
    "color_list = []\r\n",
    "missing_list = []\r\n",
    "missing_trajectory = defaultdict(list)\r\n",
    "cell_id = 0\r\n",
    "\r\n",
    "max_searching_distance = 50\r\n",
    "\r\n",
    "max_missing_ratio = 1.4\r\n",
    "min_missing_ratio = 0.71\r\n",
    "\r\n",
    "max_splitting_area_ratio = 1.3 # splitting ratio between new cell and old cell\r\n",
    "min_splitting_area_ratio = 0.1\r\n",
    "\r\n",
    "min_area = 50 # the minimum area for a new cell\r\n",
    "\r\n",
    "max_children_ratio = 1.4    # ratio between children\r\n",
    "min_children_ratio = 0.71\r\n",
    "\r\n",
    "markers_color_value_offset = 10\r\n",
    "\r\n",
    "\r\n",
    "# Do batch images segmenting\r\n",
    "for i in range(SIZE):\r\n",
    "    path_cell_subfolder = \"01\"\r\n",
    "    path_cell_name = \"t\" + format_name_digits(i) + \".tif\"\r\n",
    "    path_cell = str(image_src_path + path_divide + path_cell_subfolder + path_divide + path_cell_name)\r\n",
    "    # get_cell_segment_info(path_cell)\r\n",
    "    now_frame = get_frame_info(path_cell)\r\n",
    "\r\n",
    "    # first frame\r\n",
    "    if(i == 0):\r\n",
    "        for cell in now_frame.cell_list:\r\n",
    "            register_new_cell(cell)\r\n",
    "            now_frame.trajectory[cell.get_cell_id()].append(cell.get_centroid())\r\n",
    "\r\n",
    "    # other frames\r\n",
    "    else:\r\n",
    "        pre_frame = frame_list[i-1]\r\n",
    "        matcher = Match(pre_frame,now_frame)\r\n",
    "        match_list = matcher.match()\r\n",
    "\r\n",
    "        list_not_match_pre = []\r\n",
    "        list_not_match_now = []\r\n",
    "        list_match_pre = []\r\n",
    "        list_match_now = []\r\n",
    "\r\n",
    "        for j in range(len(match_list)):\r\n",
    "            pre_index = match_list[j][0]\r\n",
    "            now_index = match_list[j][1]\r\n",
    "\r\n",
    "            list_match_pre.append(pre_index)\r\n",
    "            list_match_now.append(now_index)\r\n",
    "\r\n",
    "        list_not_match_now = set([i for i in range(len(now_frame.cell_list))]) - set(list_match_now)\r\n",
    "        list_not_match_now = [i for i in  list_not_match_now]\r\n",
    "        list_not_match_pre = set([i for i in range(len(pre_frame.cell_list))]) - set(list_match_pre)\r\n",
    "        list_not_match_pre = [i for i in list_not_match_pre]\r\n",
    "\r\n",
    "        # detecting missing cells\r\n",
    "\r\n",
    "        for j in range(len(missing_list) - 1, -1, -1):\r\n",
    "            for k in range(len(list_not_match_now) - 1, -1, -1):\r\n",
    "                miss_cell = missing_list[j]\r\n",
    "                cell_not_match_now_index = list_not_match_now[k]\r\n",
    "                cell_not_match_now = now_frame.cell_list[cell_not_match_now_index]\r\n",
    "                area_ratio = miss_cell.area / cell_not_match_now.area\r\n",
    "                distance = cal_distance(miss_cell.centroid, cell_not_match_now.centroid)\r\n",
    "                major_ratio = miss_cell.major / cell_not_match_now.major\r\n",
    "                minor_ratio = miss_cell.minor / cell_not_match_now.minor\r\n",
    "\r\n",
    "                if (distance <= max_searching_distance and\r\n",
    "                        min_missing_ratio <= area_ratio <= max_missing_ratio and\r\n",
    "                        0.9 <= major_ratio <= 1.1 and\r\n",
    "                        0.9 <= minor_ratio <= 1.1\r\n",
    "                        ):\r\n",
    "                    # match missing cell\r\n",
    "                    cell_not_match_now.id = miss_cell.id\r\n",
    "                    now_frame.trajectory[cell_not_match_now.id] = missing_trajectory[miss_cell.id].copy()\r\n",
    "                    now_frame.trajectory[cell_not_match_now.id].append(cell_not_match_now.centroid)\r\n",
    "                    list_not_match_now.remove(cell_not_match_now_index)\r\n",
    "                    missing_list.remove(miss_cell)\r\n",
    "                    del missing_trajectory[miss_cell.id]\r\n",
    "                    break\r\n",
    "\r\n",
    "        for j in range(len(list_match_now)):\r\n",
    "\r\n",
    "            match_cell_pre_index = list_match_pre[j]\r\n",
    "            match_cell_now_index = list_match_now[j]\r\n",
    "            match_cell_pre = pre_frame.cell_list[match_cell_pre_index]\r\n",
    "            match_cell_now = now_frame.cell_list[match_cell_now_index]\r\n",
    "\r\n",
    "            # shape_matrix = matcher.shape_matrix\r\n",
    "            # distance_matrix = matcher.distance_matrix\r\n",
    "            # cost_matrix = matcher.cost_matrix\r\n",
    "\r\n",
    "            flag = True # matched successfully\r\n",
    "\r\n",
    "\r\n",
    "            # detecting mitosis\r\n",
    "\r\n",
    "            distance = []\r\n",
    "\r\n",
    "            for k in range(len(list_not_match_now)):\r\n",
    "                cell_not_match_now_index = list_not_match_now[k]\r\n",
    "                cell_not_match_now = now_frame.cell_list[cell_not_match_now_index]\r\n",
    "                distance.append([cell_not_match_now_index,\r\n",
    "                                    cal_distance(cell_not_match_now.centroid, match_cell_pre.centroid)])\r\n",
    "\r\n",
    "            distance = sorted(distance, key=lambda x: x[1])\r\n",
    "            if (len(distance) > 0):\r\n",
    "\r\n",
    "                cell_not_match_now_index = distance[0][0]\r\n",
    "                cell_not_match_now = now_frame.cell_list[cell_not_match_now_index]\r\n",
    "                area_ratio_second = cell_not_match_now.area / match_cell_pre.area\r\n",
    "                area_ratio_first = match_cell_now.area / match_cell_pre.area\r\n",
    "                area_ratio_two_component = cell_not_match_now.area / match_cell_now.area\r\n",
    "\r\n",
    "                if (distance[0][1] <= max_searching_distance\r\n",
    "                        # and shape_matrix[match_cell_pre_index][match_cell_now_index] > 0.3\r\n",
    "                        and min_children_ratio <= area_ratio_two_component <= max_children_ratio\r\n",
    "                        and min_splitting_area_ratio <= area_ratio_first <= max_splitting_area_ratio\r\n",
    "                        and min_splitting_area_ratio <= area_ratio_second <= max_splitting_area_ratio\r\n",
    "                        ):\r\n",
    "                    register_new_cell(match_cell_now)\r\n",
    "                    register_new_cell(cell_not_match_now)\r\n",
    "                    now_frame.trajectory[match_cell_now.id].append(match_cell_now.get_centroid())\r\n",
    "                    now_frame.trajectory[cell_not_match_now.id].append(cell_not_match_now.get_centroid())\r\n",
    "                    list_not_match_now.remove(cell_not_match_now_index)\r\n",
    "\r\n",
    "                    flag = False\r\n",
    "\r\n",
    "            if (flag):\r\n",
    "                match_cell_now.id = match_cell_pre.id\r\n",
    "                now_frame.trajectory[match_cell_now.id] = pre_frame.trajectory[match_cell_pre.id].copy()\r\n",
    "                now_frame.trajectory[match_cell_now.id].append(match_cell_now.get_centroid())\r\n",
    "\r\n",
    "        for j in range(len(missing_list) - 1, -1, -1):\r\n",
    "            miss_cell = missing_list[j]\r\n",
    "            if (miss_cell.missing_span < 4):\r\n",
    "                miss_cell.missing_span += 1\r\n",
    "            else:\r\n",
    "                missing_list.remove(miss_cell)\r\n",
    "                del missing_trajectory[miss_cell.id]\r\n",
    "\r\n",
    "        for j in list_not_match_pre:\r\n",
    "            miss_cell = pre_frame.cell_list[j]\r\n",
    "            missing_list.append(miss_cell)\r\n",
    "            missing_trajectory[miss_cell.id] = pre_frame.trajectory[miss_cell.id]\r\n",
    "\r\n",
    "        for j in list_not_match_now:\r\n",
    "\r\n",
    "            now_cell = now_frame.cell_list[j]\r\n",
    "            register_new_cell(now_cell)\r\n",
    "            now_frame.trajectory[now_cell.id].append(now_cell.get_centroid())\r\n",
    "\r\n",
    "    frame_list.append(now_frame)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i in range(SIZE):\r\n",
    "\r\n",
    "        frame = frame_list[i]\r\n",
    "        for key in frame.trajectory.keys():\r\n",
    "            lines = frame.trajectory[key]\r\n",
    "\r\n",
    "            if(len(lines) > 1):\r\n",
    "                for j in range(len(lines)-1):\r\n",
    "                    x1,y1 = lines[j]\r\n",
    "                    x2,y2 = lines[j+1]\r\n",
    "                    cv2.line(frame.image, (int(x1), int(y1)), (int(x2), int(y2)), color_list[key], 3)\r\n",
    "            else:\r\n",
    "                    x1,y1 = lines[0]\r\n",
    "                    cv2.circle(frame.image,(int(x1),int(y1)),1,color_list[key],3)\r\n",
    "\r\n",
    "            for cell in frame.cell_list:\r\n",
    "                cv2.drawContours(frame.image,[cell.contour],-1,color_list[cell.id],3)\r\n",
    "                if cell.underSplitting:\r\n",
    "                    cv2.circle(frame.image,tuple(cell.get_centroid().astype(int)),30,(0, 0, 255),3)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "for i in range(SIZE):\r\n",
    "    frame = frame_list[i]\r\n",
    "    cv2.imshow('labels',frame.image)\r\n",
    "    cv2.waitKey(300)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6103e0a6333ee982d0324350de5c23e21a5852468c0aab9797bd5fbeddd2c5bf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('cv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}