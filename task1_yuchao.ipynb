{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math\r\n",
    "import skimage.segmentation\r\n",
    "from skimage import color\r\n",
    "from pathlib import Path\r\n",
    "from collections import defaultdict\r\n",
    "from scipy.optimize import linear_sum_assignment\r\n",
    "\r\n",
    "import imageio.core.util\r\n",
    "\r\n",
    "\r\n",
    "def ignore_warnings(*args, **kwargs):\r\n",
    "    pass\r\n",
    "imageio.core.util._precision_warn = ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\r\n",
    "\r\n",
    "    # used for handling object information. Scalable.\r\n",
    "\r\n",
    "    split_threshold = 1.8\r\n",
    "\r\n",
    "    def __init__(self,contour,centroid,color = 0,id = -1):\r\n",
    "        self.contour = contour # a set of (x,y) coordinates making up  a contour\r\n",
    "        self.id = id\r\n",
    "        self.centroid = centroid #(x,y) co-ordinates\r\n",
    "        self.color = color\r\n",
    "        self.underSplitting = False\r\n",
    "\r\n",
    "    def get_contours(self):\r\n",
    "        return self.contour\r\n",
    "\r\n",
    "\r\n",
    "    def get_cell_id(self):\r\n",
    "        return self.id\r\n",
    "\r\n",
    "    def get_centroid(self):\r\n",
    "        return self.centroid\r\n",
    "\r\n",
    "    def get_under_splitting(self):\r\n",
    "        return self.underSplitting\r\n",
    "\r\n",
    "    def set_cell_id(self,new_id):\r\n",
    "        self.id = new_id\r\n",
    "\r\n",
    "    def set_under_splitting(self,flag):\r\n",
    "        self.underSplitting = flag\r\n",
    "\r\n",
    "    def if_splitting(self):\r\n",
    "        (x,y),(a,b), angle = cv2.fitEllipse(self.contour)\r\n",
    "        ratio = b / a\r\n",
    "\r\n",
    "        if(ratio > self.split_threshold):\r\n",
    "            self.set_under_splitting(True)\r\n",
    "\r\n",
    "\r\n",
    "class Frame:\r\n",
    "\r\n",
    "    def __init__(self, image):\r\n",
    "        self.image = image\r\n",
    "        self.cell_list = []\r\n",
    "        self.trajectory = defaultdict(list)\r\n",
    "\r\n",
    "class Match:\r\n",
    "\r\n",
    "    distance_threshold = 50 # used for normalizing & threshold\r\n",
    "    alpha_1 = 1\r\n",
    "    alpha_2 = 0.5\r\n",
    "\r\n",
    "    def __init__(self,frame_pre,frame_now):\r\n",
    "        self.frame_pre = frame_pre\r\n",
    "        self.frame_now = frame_now\r\n",
    "\r\n",
    "    def set_distance_threshold(self,new_threshold):\r\n",
    "        self.distance_threshold = new_threshold\r\n",
    "\r\n",
    "    def set_distance_factor(self,new_factor):\r\n",
    "        self.alpha_1 = new_factor\r\n",
    "\r\n",
    "    def set_shape_factor(self,new_factor):\r\n",
    "        self.alpha_2 = new_factor\r\n",
    "\r\n",
    "    def cal_distance_cost(self,distance_thresh):\r\n",
    "\r\n",
    "        size_pre = len(self.frame_pre.cell_list)\r\n",
    "        size_now = len(self.frame_now.cell_list)\r\n",
    "\r\n",
    "        distance_matrix = np.zeros((size_pre, size_now))\r\n",
    "\r\n",
    "        # Euclidean Distance\r\n",
    "        for i in range(size_pre):\r\n",
    "            for j in range(size_now):\r\n",
    "                x1, y1 = self.frame_pre.cell_list[i].centroid\r\n",
    "                x2, y2 = self.frame_now.cell_list[j].centroid\r\n",
    "                distance = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\r\n",
    "                distance_matrix[i][j] = distance / distance_thresh if distance < distance_thresh \\\r\n",
    "                    else 1\r\n",
    "\r\n",
    "        return distance_matrix\r\n",
    "\r\n",
    "    # def cal_cost_matrix(self):\r\n",
    "    #     distance_matrix = self.cal_distance_cost(self.distance_threshold)\r\n",
    "    #     cost_matrix = self.alpha_1 * distance_matrix\r\n",
    "\r\n",
    "        # return  cost_matrix\r\n",
    "\r\n",
    "    def match(self):\r\n",
    "        distance_matrix = self.cal_distance_cost(self.distance_threshold)\r\n",
    "        cost_matrix = self.alpha_1 * distance_matrix\r\n",
    "\r\n",
    "        match_result = linear_sum_assignment(cost_matrix)\r\n",
    "        # print(match_list)\r\n",
    "        shape = np.shape(match_result)\r\n",
    "        match_list = []\r\n",
    "        for i in range(shape[1]):\r\n",
    "            node_pre = match_result[0][i]\r\n",
    "            node_now = match_result[1][i]\r\n",
    "            if(distance_matrix[node_pre][node_now] == 1):\r\n",
    "                continue\r\n",
    "            match_list.append([node_pre,node_now])\r\n",
    "\r\n",
    "        return match_list\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "frame_list = []\r\n",
    "color_list = []\r\n",
    "cell_id = 0\r\n",
    "markers_color_value_offset = 10\r\n",
    "\r\n",
    "def get_binary(\r\n",
    "    input_image: np.array, \r\n",
    "    min_cell_pixel_portion = 1/8, \r\n",
    "    threshold_block_size = 35\r\n",
    "):\r\n",
    "    '''\r\n",
    "    min_cell_pixel_portion: Decreasing this value will make smaller pixel value chunks considered as cell\r\n",
    "    threshold_block_size: Increasing this value will let larger size of chunk being considered as cell, \r\n",
    "    but will lose detailed edges at the same time\r\n",
    "    '''\r\n",
    "    input = input_image.copy()\r\n",
    "    # Get meaningful range\r\n",
    "    meaningful_range = np.max(input) - np.min(input)\r\n",
    "    # Assume certain small portion of the max_pixel_value is the minimum cell pixel value\r\n",
    "    min_cell_pixel = math.ceil(meaningful_range * min_cell_pixel_portion)\r\n",
    "    # normalize image based on the acquired meaningful range\r\n",
    "    input_norm = cv2.normalize(input, None, alpha=0, beta=meaningful_range, norm_type=cv2.NORM_MINMAX)\r\n",
    "    input_norm[input_norm < min_cell_pixel] = 0\r\n",
    "    input_binary = cv2.adaptiveThreshold(\r\n",
    "        input_norm,meaningful_range,\r\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\r\n",
    "        cv2.THRESH_BINARY,\r\n",
    "        threshold_block_size,\r\n",
    "        0\r\n",
    "    )\r\n",
    "    return input_binary\r\n",
    "\r\n",
    "def get_reduce_noise_by_closing(input_binary: np.array, kernel_size_closing = (5,5), iterations = 5):\r\n",
    "    '''\r\n",
    "    Try dilate and erode: closing\r\n",
    "    1. Dilate the objects first to get rid of the noise inside each objects\r\n",
    "    2. Erode the objects with same degree to decrease the size to original state\r\n",
    "    '''\r\n",
    "    input_closing = input_binary.copy()\r\n",
    "    kernel = np.ones(kernel_size_closing,np.uint8)\r\n",
    "    input_closing = cv2.morphologyEx(input_closing, cv2.MORPH_CLOSE, kernel, iterations)\r\n",
    "    return input_closing\r\n",
    "\r\n",
    "def get_reduce_noise_by_opening(input_binary: np.array, kernel_size_opening = (7,7), iterations = 5):\r\n",
    "    '''\r\n",
    "    Try erode and dilate: opening\r\n",
    "    Erode then dilate\r\n",
    "    '''\r\n",
    "    input_opening = input_binary.copy()\r\n",
    "    kernel = np.ones(kernel_size_opening,np.uint8)\r\n",
    "    input_opening = cv2.morphologyEx(input_opening, cv2.MORPH_OPEN, kernel, iterations)\r\n",
    "    return input_opening\r\n",
    "\r\n",
    "def find_contours(\r\n",
    "        input_image: np.array,\r\n",
    "        input_binary: np.array, \r\n",
    "        kernel_size_bg = (3, 3),\r\n",
    "        iterations_bg = 7,\r\n",
    "        kernel_size_dist_erode = (3, 3),\r\n",
    "        iterations_dist_erode = 4\r\n",
    "    ):\r\n",
    "    global markers_color_value_offset\r\n",
    "    '''\r\n",
    "    Find all of the contours of the input image cell and draw the contours\r\n",
    "    '''\r\n",
    "    kernel = np.ones(kernel_size_bg, np.uint8)\r\n",
    "    sure_bg = cv2.dilate(input_binary, kernel, iterations=iterations_bg)\r\n",
    "    dist_transform = cv2.distanceTransform(input_binary,cv2.DIST_MASK_3,5)\r\n",
    "    dist_transform_erode = cv2.erode(dist_transform, kernel_size_dist_erode, iterations = iterations_dist_erode)\r\n",
    "    sure_fg = np.uint8(dist_transform_erode)  #Convert to uint8 from float\r\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\r\n",
    "    markers_amount, markers = cv2.connectedComponents(\r\n",
    "        sure_fg, \r\n",
    "        4 # use connectivity of 4 instead of 8 to decrease close cells attaching probability\r\n",
    "    )\r\n",
    "    '''\r\n",
    "    object_amount_not_on_borders:\r\n",
    "    1. The total amount of objects detected in the image without considering the ones on borders\r\n",
    "    2. Need to use markers_amount - 1 since markers_amount includes the background\r\n",
    "    '''\r\n",
    "    object_amount_not_on_borders = markers_amount - 1\r\n",
    "\r\n",
    "    # make sure the background are not set as 0 and consider as unsured area\r\n",
    "    markers = markers + markers_color_value_offset\r\n",
    "    max_unkown = np.max(unknown)\r\n",
    "    markers[unknown==max_unkown] = 0\r\n",
    "\r\n",
    "    watershed = cv2.watershed(input_image, markers)\r\n",
    "\r\n",
    "    # watershed boundaries are -1\r\n",
    "    edges = np.zeros(input_binary.shape, np.uint8)\r\n",
    "    edges[watershed == -1] = 1\r\n",
    "\r\n",
    "    #label2rgb - Return an RGB image where color-coded labels are painted over the image.\r\n",
    "    colored_segmentation = color.label2rgb(watershed, bg_label=0)\r\n",
    "\r\n",
    "    return watershed, edges, colored_segmentation, object_amount_not_on_borders\r\n",
    "\r\n",
    "def get_object_pixel_record(object_color_array):\r\n",
    "    # Get useful pixel values\r\n",
    "    unique_objects = np.unique(object_color_array)\r\n",
    "    unique_objects = unique_objects[unique_objects >= 1] \r\n",
    "\r\n",
    "    # initialize the pixel dict with all object count starting from 0\r\n",
    "    object_dict = dict.fromkeys(unique_objects)\r\n",
    "    for key in object_dict:\r\n",
    "        object_dict[key] = 0\r\n",
    "\r\n",
    "    # get the pixel value count for each object key label\r\n",
    "    for row in object_color_array:\r\n",
    "        for col in row:\r\n",
    "            if col >= 1:\r\n",
    "                object_dict[col] += 1\r\n",
    "    return object_dict\r\n",
    "\r\n",
    "def format_name_digits(number: int):\r\n",
    "    number_str = '000'\r\n",
    "    if number < 10:\r\n",
    "        number_str = '00' + str(number)\r\n",
    "    elif number >= 10 and number <= 99: \r\n",
    "        number_str = '0' + str(number)\r\n",
    "    elif number >= 100 and number <= 999:\r\n",
    "        number_str = str(number)\r\n",
    "    else:\r\n",
    "        print(\"TOO BIG NUMBER for format_name_digits:\", number)\r\n",
    "    return number_str\r\n",
    "\r\n",
    "def get_frame_info(path_cell: str):\r\n",
    "    # Read as gray\r\n",
    "    cell_original = cv2.imread(path_cell)\r\n",
    "    cell = cv2.imread(path_cell, cv2.IMREAD_GRAYSCALE)\r\n",
    "\r\n",
    "    # Turn into np array first\r\n",
    "    cell = np.array(cell)\r\n",
    "\r\n",
    "    # Grey image to binary\r\n",
    "    cell_binary = get_binary(cell)\r\n",
    "\r\n",
    "    # reduce noise\r\n",
    "    cell_binary_opening = get_reduce_noise_by_opening(cell_binary)\r\n",
    "    cell_no_noise = cell_binary_opening.copy()\r\n",
    "\r\n",
    "    # removing border interfered cells\r\n",
    "    cell_no_border = skimage.segmentation.clear_border(cell_no_noise)\r\n",
    "\r\n",
    "    # get segmentation info WITH cells on boundaries considered\r\n",
    "    cell_watershed, cell_edges, cell_colored_segmentation, cell_amount = find_contours(cell_original, cell_no_noise)\r\n",
    "\r\n",
    "    # get segmentation info WITHOUT cells on boundaries considered\r\n",
    "    cell_watershed_no_border, cell_edges_no_border, cell_colored_segmentation_no_border, cell_amount_no_border = find_contours(\r\n",
    "        cell_original, cell_no_border)\r\n",
    "\r\n",
    "    # After minus markers_color_value_offset, all of the objects color pixel will have value >= 1\r\n",
    "    labels = np.unique(cell_watershed_no_border)\r\n",
    "\r\n",
    "    cell_watershed_no_border = cell_watershed_no_border - markers_color_value_offset\r\n",
    "\r\n",
    "    labels = np.unique(cell_watershed_no_border)\r\n",
    "    cell_img = np.zeros_like(cell_no_border)\r\n",
    "    cell_img[cell_no_border > 0] = 255\r\n",
    "    cell_img = cv2.cvtColor(cell_img,cv2.COLOR_GRAY2RGB)\r\n",
    "\r\n",
    "    frame = Frame(cell_img)\r\n",
    "    for label in labels:\r\n",
    "        if label <= 0:\r\n",
    "            continue\r\n",
    "        segment = np.zeros_like(cell_watershed_no_border)\r\n",
    "        segment = np.uint8(segment)\r\n",
    "        segment[cell_watershed_no_border == label] = 255\r\n",
    "        contours, _ = cv2.findContours(segment, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\r\n",
    "        _, _, _, centroids = cv2.connectedComponentsWithStats(segment)\r\n",
    "        cell = Cell(contours[0],centroids[1])\r\n",
    "\r\n",
    "        # check if the cell is splitting\r\n",
    "        cell.if_splitting()\r\n",
    "        frame.cell_list.append(cell)\r\n",
    "\r\n",
    "    return frame\r\n",
    "'''\r\n",
    "regu\r\n",
    "'''\r\n",
    "def register_new_cell(cell:Cell,cell_id):\r\n",
    "    cell.set_cell_id(cell_id)\r\n",
    "    cell.color = np.random.randint(low = 0,high =255,size = 3).tolist()\r\n",
    "    global color_list\r\n",
    "    color_list.append(cell.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image root path str(Path(file_path).parent.resolve()) + \r\n",
    "image_src_path = str(\".\\Sequences\")\r\n",
    "# individual image path example\\\r\n",
    "path_divide = \"\\\\\"\r\n",
    "path_cell_subfolder = \"01\"\r\n",
    "path_cell_name = \"t000.tif\"\r\n",
    "path_cell = str(image_src_path + path_divide + path_cell_subfolder + path_divide + path_cell_name)\r\n",
    "\r\n",
    "\r\n",
    "for i in range(0, 60):\r\n",
    "    path_cell_subfolder = \"01\"\r\n",
    "    path_cell_name = \"t\" + format_name_digits(i) + \".tif\"\r\n",
    "    path_cell = str(image_src_path + path_divide + path_cell_subfolder + path_divide + path_cell_name)\r\n",
    "    now_frame = get_frame_info(path_cell)\r\n",
    "\r\n",
    "    # first frame\r\n",
    "    if(i == 0):\r\n",
    "        for cell in now_frame.cell_list:\r\n",
    "            register_new_cell(cell,cell_id)\r\n",
    "            cell_id += 1\r\n",
    "            now_frame.trajectory[cell.get_cell_id()].append(cell.get_centroid())\r\n",
    "\r\n",
    "    # other frames\r\n",
    "    elif (i < 60):\r\n",
    "        pre_frame = frame_list[i-1]\r\n",
    "        matcher = Match(pre_frame,now_frame)\r\n",
    "        match_list = matcher.match()\r\n",
    "\r\n",
    "        list_not_match_now = []\r\n",
    "        list_match_now = []\r\n",
    "\r\n",
    "        for j in range(len(match_list)):\r\n",
    "            pre_index = match_list[j][0]\r\n",
    "            now_index = match_list[j][1]\r\n",
    "\r\n",
    "            pre_cell = pre_frame.cell_list[pre_index]\r\n",
    "            now_cell = now_frame.cell_list[now_index]\r\n",
    "\r\n",
    "            list_match_now.append(now_index)\r\n",
    "\r\n",
    "            if (pre_cell.underSplitting) and  (now_cell.underSplitting):\r\n",
    "                register_new_cell(now_cell,cell_id)\r\n",
    "                cell_id +=1\r\n",
    "                now_frame.trajectory[now_cell.id].append(now_cell.get_centroid())\r\n",
    "\r\n",
    "            else:\r\n",
    "                now_cell.id = pre_cell.id\r\n",
    "                now_frame.trajectory[now_cell.id] = pre_frame.trajectory[pre_cell.id].copy()\r\n",
    "                now_frame.trajectory[now_cell.id].append(now_cell.get_centroid())\r\n",
    "\r\n",
    "        list_not_match_now = set([i for i in range(len(now_frame.cell_list))]) - set(list_match_now)\r\n",
    "\r\n",
    "        for j in list_not_match_now:\r\n",
    "            now_cell = now_frame.cell_list[j]\r\n",
    "            register_new_cell(now_cell,cell_id)\r\n",
    "            cell_id += 1\r\n",
    "            now_frame.trajectory[now_cell.id].append(now_cell.get_centroid())\r\n",
    "    else:\r\n",
    "        break\r\n",
    "\r\n",
    "    frame_list.append(now_frame)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\r\n",
    "\r\n",
    "    frame = frame_list[i]\r\n",
    "    for key in frame.trajectory.keys():\r\n",
    "        lines = frame.trajectory[key]\r\n",
    "\r\n",
    "        if(len(lines) > 1):\r\n",
    "            for j in range(len(lines)-1):\r\n",
    "                x1,y1 = lines[j]\r\n",
    "                x2,y2 = lines[j+1]\r\n",
    "                cv2.line(frame.image, (int(x1), int(y1)), (int(x2), int(y2)), color_list[key], 3)\r\n",
    "        else:\r\n",
    "            x1,y1 = lines[0]\r\n",
    "            cv2.circle(frame.image,(int(x1),int(y1)),1,color_list[key],3)\r\n",
    "        cv2.putText(frame.image,str(key), (int(x1)+20,int(y1)),cv2.FONT_HERSHEY_SIMPLEX,0.8,color_list[key],3)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,20):\r\n",
    "\r\n",
    "    frame = frame_list[i]\r\n",
    "    cv2.imshow('labels',frame.image)\r\n",
    "    cv2.waitKey(500)\r\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dde9d3faee4fdb5efba3dec7c2756105b1b1df2d91f113b9dd18f8e133bcc617"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('bo': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}